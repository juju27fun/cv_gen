"""
Client robuste pour l'API Reactive Resume
Impl√©mente les bonnes pratiques du PDF_GENERATION_GUIDE.md
"""

import asyncio
import logging
import time
from typing import Dict, Any, Optional
from pathlib import Path
import aiohttp
from aiohttp import ClientSession, ClientError, ClientTimeout
# Utilisons Pydantic v1 pour √©viter les probl√®mes de compatibilit√©
from pydantic.v1 import BaseSettings, Field

logger = logging.getLogger(__name__)

# Import pour async file operations
try:
    import aiofiles
except ImportError:
    aiofiles = None
    logger.warning("aiofiles non disponible, certaines fonctionnalit√©s seront limit√©es")


class Settings(BaseSettings):
    """Configuration pour Reactive Resume"""
    reactive_resume_url: str = Field(default="http://localhost:3000", env="REACTIVE_RESUME_URL")
    reactive_resume_timeout: int = Field(default=30, env="REACTIVE_RESUME_TIMEOUT")
    max_retries: int = Field(default=3, env="REACTIVE_RESUME_MAX_RETRIES")
    retry_delay: float = Field(default=1.0, env="REACTIVE_RESUME_RETRY_DELAY")

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


class ReactiveResumeError(Exception):
    """Erreur personnalis√©e pour Reactive Resume"""
    pass


class ReactiveResumeClient:
    """
    Client robuste pour l'API Reactive Resume

    Impl√©mente:
    - Retry logic avec backoff exponentiel
    - Gestion d'erreurs avanc√©e
    - Validation des donn√©es
    - Logging structur√©
    - Timeout configurable
    """

    def __init__(self, base_url: Optional[str] = None, timeout: int = 30, max_retries: int = 3):
        """
        Initialise le client Reactive Resume

        Args:
            base_url: URL de base de l'API (ex: http://localhost:3000)
            timeout: Timeout en secondes pour les requ√™tes
            max_retries: Nombre maximum de tentatives en cas d'√©chec
        """
        settings = Settings()
        self.base_url = base_url or settings.reactive_resume_url
        self.api_url = f"{self.base_url}/api"
        self.timeout = timeout
        self.max_retries = max_retries
        self.retry_delay = settings.retry_delay

        logger.info(f"ReactiveResumeClient initialis√©: {self.base_url}")

    async def create_resume(self, session: ClientSession, resume_data: Dict[str, Any], title: str = "CV G√©n√©r√©", slug: str = None) -> str:
        """
        Cr√©e un nouveau resume et retourne son ID

        Args:
            session: Session aiohttp active
            resume_data: Donn√©es JSON du resume
            title: Titre du CV
            slug: Slug unique pour le CV (g√©n√©r√© automatiquement si non fourni)

        Returns:
            ID du resume cr√©√©

        Raises:
            ReactiveResumeError: En cas d'erreur lors de la cr√©ation
        """
        logger.info("Cr√©ation d'un nouveau resume...")

        # G√©n√©rer un slug unique si non fourni
        if not slug:
            import time
            slug = f"cv-{int(time.time())}"

        # Pr√©parer les donn√©es selon le format de l'API Reactive Resume
        import_data = {
            "title": title,
            "slug": slug,
            "visibility": "private",
            "data": resume_data
        }

        try:
            async with session.post(
                f"{self.api_url}/resume/import",
                json=import_data,
                headers={"Content-Type": "application/json"},
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:

                if response.status == 201:
                    result = await response.json()
                    resume_id = result.get("id")
                    logger.info(f"Resume cr√©√© avec succ√®s: {resume_id}")
                    return resume_id
                elif response.status == 400:
                    error_text = await response.text()
                    logger.error(f"Donn√©es invalides (400): {error_text}")
                    raise ReactiveResumeError(f"Donn√©es invalides: {error_text}")
                elif response.status == 401:
                    logger.warning("Non autoris√© - Authentification requise pour Reactive Resume")
                    logger.info("Le CV JSON sera sauvegard√© sans g√©n√©ration PDF")
                    return None  # Indique qu'il faut utiliser le fallback
                elif response.status == 404:
                    logger.error("Endpoint non trouv√©")
                    raise ReactiveResumeError("Endpoint non trouv√© - V√©rifiez l'URL de l'API")
                elif response.status >= 500:
                    error_text = await response.text()
                    logger.error(f"Erreur serveur {response.status}: {error_text}")
                    raise ReactiveResumeError(f"Erreur serveur {response.status}: {error_text}")
                else:
                    error_text = await response.text()
                    logger.error(f"Erreur HTTP {response.status}: {error_text}")
                    raise ReactiveResumeError(f"Erreur HTTP {response.status}: {error_text}")

        except asyncio.TimeoutError:
            logger.error(f"Timeout lors de la cr√©ation du resume (> {self.timeout}s)")
            raise ReactiveResumeError(f"Timeout lors de la cr√©ation du resume")
        except ClientError as e:
            logger.error(f"Erreur r√©seau: {str(e)}")
            raise ReactiveResumeError(f"Erreur r√©seau: {str(e)}")

    async def generate_pdf(self, session: ClientSession, resume_id: str) -> bytes:
        """
        G√©n√®re et r√©cup√®re le PDF du resume

        Args:
            session: Session aiohttp active
            resume_id: ID du resume

        Returns:
            Bytes du PDF

        Raises:
            ReactiveResumeError: En cas d'erreur lors de la g√©n√©ration
        """
        logger.info(f"G√©n√©ration du PDF pour le resume {resume_id}...")

        # Attendre que le resume soit trait√©
        await asyncio.sleep(2)

        try:
            async with session.get(
                f"{self.api_url}/resume/print/{resume_id}",
                headers={"Accept": "application/pdf"},
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:

                if response.status == 200:
                    pdf_content = await response.read()
                    logger.info(f"PDF g√©n√©r√© avec succ√®s ({len(pdf_content)} bytes)")
                    return pdf_content
                elif response.status == 404:
                    logger.error(f"Resume {resume_id} non trouv√©")
                    raise ReactiveResumeError(f"Resume {resume_id} non trouv√©")
                elif response.status >= 500:
                    error_text = await response.text()
                    logger.error(f"Erreur serveur {response.status}: {error_text}")
                    raise ReactiveResumeError(f"Erreur serveur {response.status}: {error_text}")
                else:
                    error_text = await response.text()
                    logger.error(f"Erreur HTTP {response.status}: {error_text}")
                    raise ReactiveResumeError(f"Erreur HTTP {response.status}: {error_text}")

        except asyncio.TimeoutError:
            logger.error(f"Timeout lors de la g√©n√©ration du PDF (> {self.timeout}s)")
            raise ReactiveResumeError(f"Timeout lors de la g√©n√©ration du PDF")
        except ClientError as e:
            logger.error(f"Erreur r√©seau: {str(e)}")
            raise ReactiveResumeError(f"Erreur r√©seau: {str(e)}")

    async def generate_pdf_preview(self, session: ClientSession, resume_id: str) -> bytes:
        """
        G√©n√®re et r√©cup√®re l'aper√ßu (HTML) du resume

        Args:
            session: Session aiohttp active
            resume_id: ID du resume

        Returns:
            Bytes de l'aper√ßu HTML
        """
        logger.info(f"G√©n√©ration de l'aper√ßu pour le resume {resume_id}...")

        try:
            async with session.get(
                f"{self.api_url}/resume/print/{resume_id}/preview",
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:

                if response.status == 200:
                    preview_content = await response.read()
                    logger.info(f"Aper√ßu g√©n√©r√© avec succ√®s ({len(preview_content)} bytes)")
                    return preview_content
                else:
                    error_text = await response.text()
                    logger.error(f"Erreur HTTP {response.status}: {error_text}")
                    raise ReactiveResumeError(f"Erreur HTTP {response.status}: {error_text}")

        except asyncio.TimeoutError:
            logger.error(f"Timeout lors de la g√©n√©ration de l'aper√ßu (> {self.timeout}s)")
            raise ReactiveResumeError(f"Timeout lors de la g√©n√©ration de l'aper√ßu")
        except ClientError as e:
            logger.error(f"Erreur r√©seau: {str(e)}")
            raise ReactiveResumeError(f"Erreur r√©seau: {str(e)}")

    async def get_resume(self, session: ClientSession, resume_id: str) -> Dict[str, Any]:
        """
        R√©cup√®re les donn√©es d'un resume

        Args:
            session: Session aiohttp active
            resume_id: ID du resume

        Returns:
            Donn√©es du resume
        """
        logger.info(f"R√©cup√©ration du resume {resume_id}...")

        try:
            async with session.get(
                f"{self.api_url}/resume/{resume_id}",
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as response:

                if response.status == 200:
                    resume_data = await response.json()
                    logger.info(f"Resume r√©cup√©r√© avec succ√®s")
                    return resume_data
                else:
                    error_text = await response.text()
                    logger.error(f"Erreur HTTP {response.status}: {error_text}")
                    raise ReactiveResumeError(f"Erreur HTTP {response.status}: {error_text}")

        except asyncio.TimeoutError:
            logger.error(f"Timeout lors de la r√©cup√©ration du resume (> {self.timeout}s)")
            raise ReactiveResumeError(f"Timeout lors de la r√©cup√©ration du resume")
        except ClientError as e:
            logger.error(f"Erreur r√©seau: {str(e)}")
            raise ReactiveResumeError(f"Erreur r√©seau: {str(e)}")

    async def check_health(self) -> bool:
        """
        V√©rifie que Reactive Resume est accessible

        Returns:
            True si accessible, False sinon
        """
        logger.info("V√©rification de la sant√© de Reactive Resume...")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.base_url}/api/health",
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    if response.status == 200:
                        logger.info("‚úÖ Reactive Resume est accessible")
                        return True
                    else:
                        logger.warning(f"‚ö†Ô∏è Reactive Resume r√©pond avec code {response.status}")
                        return False
        except Exception as e:
            logger.error(f"‚ùå Reactive Resume non accessible: {str(e)}")
            return False

    async def create_and_generate_pdf(
        self,
        resume_data: Dict[str, Any],
        output_path: Path,
        title: str = None
    ) -> Path:
        """
        Cr√©e un resume et g√©n√®re son PDF en une seule op√©ration

        Args:
            resume_data: Donn√©es JSON du resume
            output_path: Chemin o√π sauvegarder le PDF
            title: Titre du CV (g√©n√©r√© automatiquement depuis output_path si non fourni)

        Returns:
            Chemin vers le PDF g√©n√©r√©

        Raises:
            ReactiveResumeError: En cas d'erreur
        """
        logger.info(f"G√©n√©ration compl√®te du CV: {output_path}")

        # G√©n√©rer le titre depuis le nom du fichier si non fourni
        if not title:
            title = output_path.stem.replace('_', ' ').replace('-', ' ').title()

        for attempt in range(self.max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    # √âtape 1: Cr√©er le resume
                    resume_id = await self.create_resume(session, resume_data, title=title)

                    # Si l'authentification a √©chou√© (resume_id = None), utiliser le fallback
                    if resume_id is None:
                        logger.info("üìÑ Sauvegarde du CV JSON (fallback sans PDF)")
                        json_path = output_path.with_suffix('.json')
                        json_path.parent.mkdir(parents=True, exist_ok=True)
                        if aiofiles:
                            async with aiofiles.open(json_path, 'w', encoding='utf-8') as f:
                                import json
                                await f.write(json.dumps(resume_data, indent=2, ensure_ascii=False))
                        else:
                            import json
                            with open(json_path, 'w', encoding='utf-8') as f:
                                json.dump(resume_data, f, indent=2, ensure_ascii=False)
                        logger.info(f"üíæ CV JSON sauvegard√©: {json_path}")
                        return json_path

                    # √âtape 2: G√©n√©rer le PDF
                    pdf_content = await self.generate_pdf(session, resume_id)

                    # √âtape 3: Sauvegarder
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    async with aiofiles.open(output_path, 'wb') as f:
                        await f.write(pdf_content)

                    logger.info(f"‚úÖ PDF g√©n√©r√© avec succ√®s: {output_path}")
                    return output_path

            except ReactiveResumeError as e:
                if attempt < self.max_retries - 1:
                    wait_time = self.retry_delay * (2 ** attempt)  # Backoff exponentiel
                    logger.warning(f"Tentative {attempt + 1}/{self.max_retries} √©chou√©e: {e}")
                    logger.info(f"‚è≥ Retry dans {wait_time}s...")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"‚ùå √âchec apr√®s {self.max_retries} tentatives")
                    raise ReactiveResumeError(f"√âchec apr√®s {self.max_retries} tentatives: {e}")

        # Cette ligne ne devrait jamais √™tre atteinte, mais pour la forme
        raise ReactiveResumeError("Nombre de tentatives d√©pass√©")


# Fonctions utilitaires pour compatibilit√© avec l'ancien code
async def generate_cv_with_retry(
    resume_data: Dict[str, Any],
    output_path: str,
    max_retries: int = 3
) -> str:
    """
    G√©n√®re un CV PDF avec retry en cas d'√©chec

    Args:
        resume_data: Donn√©es du CV
        output_path: Chemin de sortie
        max_retries: Nombre maximum de tentatives

    Returns:
        Chemin du PDF g√©n√©r√©
    """
    client = ReactiveResumeClient(max_retries=max_retries)
    output_path_obj = Path(output_path)

    try:
        result_path = await client.create_and_generate_pdf(resume_data, output_path_obj)
        return str(result_path)
    except ReactiveResumeError:
        # Fallback: sauvegarde du JSON
        if aiofiles:
            json_path = output_path_obj.with_suffix('.json')
            import json
            async with aiofiles.open(json_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(resume_data, indent=2, ensure_ascii=False))
            logger.warning(f"üíæ JSON sauvegard√© √† la place: {json_path}")
            return str(json_path)
        else:
            # Fallback synchrone
            json_path = output_path_obj.with_suffix('.json')
            import json
            json_path.parent.mkdir(parents=True, exist_ok=True)
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(resume_data, f, indent=2, ensure_ascii=False)
            logger.warning(f"üíæ JSON sauvegard√© √† la place: {json_path}")
            return str(json_path)
